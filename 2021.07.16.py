# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10xmVBL2y9fhM9I3t61YBFgowFcm8bEhk
"""

from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split

data = load_boston()
xTrain, xTest, yTrain, yTest\
    = train_test_split(data.data, data.target, random_state=42)
data.feature_names

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(xTrain, yTrain)

score = model.score(xTest, yTest)
print("정확도: ", score)

coefficient = model.coef_
intercept = model.intercept_
print("계수 : \n", coefficient)
print()
print("절편 : \n", intercept)

from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split

data = load_diabetes()
xTrain, xTest, yTrain, yTest\
    = train_test_split(data.data, data.target, random_state=42)
print(data, "\n", data.target.size)

from sklearn.linear_model import Ridge

ridge = Ridge(alpha=1.0)
ridge.fit(xTrain, yTrain)

score = ridge.score(xTest, yTest)
print("정확도: ", score)

from sklearn.linear_model import Lasso

lasso = Lasso(alpha=1.0)
lasso.fit(xTrain, yTrain)

score = lasso.score(xTest, yTest)
print("정확도: ", score)

from sklearn.linear_model import ElasticNet

elastic = ElasticNet(alpha=1.0, l1_ratio=0.5)
elastic.fit(xTrain, yTrain)

score = elastic.score(xTest, yTest)
print("정확도: ", score)

from sklearn.linear_model import LinearRegression
import pandas as pd
import numpy as np

linear = LinearRegression()
linear.fit(xTrain, yTrain)

score = linear.score(xTest, yTest)
print("정확도: ", score)


coefficients = np.vstack((linear.coef_, ridge.coef_, lasso.coef_, elastic.coef_))
index = ["linear", "ridge", "lasso", "elastic"]
coefficients_df = pd.DataFrame(coefficients, columns=data.feature_names, index=index)

print("정규화 선형회귀 모델별 가중치(계수) 비교")
coefficients_df

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import pandas as pd

dataset = load_iris()
data = pd.DataFrame(dataset.data, columns=dataset.feature_names)
xTrain, xTest, yTrain, yTest = train_test_split(data, dataset.target, random_state=42)

import matplotlib.pyplot as plt

xTrain.plot(kind="box")
plt.title("xTrain")
plt.show()
xTest.plot(kind="box")
plt.title("xTest")
plt.show()

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
xTrainScaled = mms.fit_transform(xTrain)
xTestScaled = mms.fit_transform(xTest)
xTestScaled

from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier(n_neighbors = 5)
model.fit(xTrainScaled, yTrain)

from sklearn.metrics import accuracy_score

pred = model.predict(xTestScaled)
accuracy_score(yTest, pred)

from sklearn.datasets import load_breast_cancer
import pandas as pd

dataset = load_breast_cancer()
train = pd.DataFrame(dataset.data, columns=dataset.feature_names)
target = pd.DataFrame(dataset.target, columns=["cancer"])
data = pd.concat([train, target], axis=1)
data.info()

from sklearn.model_selection import train_test_split
xTrain, xTest, yTrain, yTest = train_test_split(
    data[["mean radius"]], data[["cancer"]], random_state=42)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver="liblinear")
model.fit(xTrain, yTrain)

from sklearn.metrics import accuracy_score
pred = model.predict(xTest)
acc = accuracy_score(yTest, pred)
print("mean radius 만으로 예측한 결과:{}\n".format(acc), pred)

from seaborn import lmplot
import matplotlib.pyplot as plt

lmplot(x="mean radius", y="cancer", data=data, logistic=True)
plt.show()

xTrain, xTest, yTrain, yTest = train_test_split(data.loc[:,:"cancer"], 
                                                data.loc[:,"cancer"], 
                                                random_state=42)
model.fit(xTrain, yTrain)
yPred = model.predict(xTest)
score = model.score(xTest, yTest)

print(f"전체 데이터로 예측한 결과: {score}")

########################################################################
import seaborn as sns

data = sns.load_dataset("titanic")
data.head()

predData = data.drop(columns=["alive", "who", "adult_male", "class", "embark_town"])
predData.drop("deck", axis = 1, inplace=True)
predData.head()

predData = predData.dropna().reset_index(drop=True)
predData.info()

#p. 338페이지부터...
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

le = LabelEncoder()
predData["sex"] = le.fit_transform(predData["sex"])
predData.tail()

embarkedUniq = predData.embarked.unique()
print("embarked열의 고유한 값:\n", embarkedUniq)
ohe = OneHotEncoder()
embarked_df = predData[["embarked"]]

ohe.fit(embarked_df)
embarked_ohe = ohe.transform(embarked_df)
embarked_ohe

embarked_df = pd.DataFrame(embarked_ohe.toarray(), columns=embarkedUniq)
embarked_df.sample(5)

predData = pd.concat([predData, embarked_df], axis=1)
predData = predData.drop("embarked", axis=1)
predData

from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(predData.iloc[:,1:], predData.iloc[:, 0], random_state=42)

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(max_depth=2)
model.fit(xTrain, yTrain)

score = model.score(xTest, yTest)
print("정확도: ", score)

import numpy as np
import matplotlib.pyplot as plt

print("피처 중요도: \n", model.feature_importances_)

n_features = xTrain.shape[1]
plt.barh(np.arange(n_features), model.feature_importances_, align="center")
plt.yticks(np.arange(n_features), xTrain.columns)
plt.xlabel("피처중요도")
plt.ylabel("피처")
plt.ylim(-1, n_features)

from sklearn.tree import plot_tree

plt.figure(figsize=(8,6))
plot_tree(model.fit(xTrain, yTrain))
plt.show()

import graphviz
from sklearn.tree import  export_graphviz

dotData = export_graphviz(model, out_file=None, feature_names = xTrain.columns, 
                          class_names=["사망", "생존"], filled=True, rounded=True, 
                          special_characters=True)
graph = graphviz.Source(dotData)
graph

!wget https://www.kaggle.com/nicolausboby/weathernominal?select=weather.nominal.csv

!pwd

import pandas as pd
data = pd.read_csv("./weather.nominal.csv", sep=",")
data.info()

data

outlook_tab = pd.crosstab(data["play"], data["outlook"])
outlook_tab

temp_tab = pd.crosstab(data["play"], data["temperature"])
temp_tab

humid_tab = pd.crosstab(data["play"], data["humidity"])
humid_tab

windy_tab = pd.crosstab(data["play"], data["windy"])
windy_tab

joined_tab = outlook_tab.join(temp_tab)
joined_tab

joined_tab = joined_tab.join(humid_tab).join(windy_tab)
joined_tab

joined_tab.iloc[0,:] = joined_tab.iloc[0,:].apply(lambda y:y/5)
joined_tab.iloc[0,:]

joined_tab.iloc[1,:] = joined_tab.iloc[1,:].apply(lambda y:y/9)
joined_tab.iloc[1,:]

joined_tab

"""P(Sunny, Mild, High, True | Yes) = 0.22×0.44×0.33×0.33×9/14 = 0.01 (0.00677)
P(Sunny, Mild, High, True | No) = 0.6×0.4×0.8×0.6×5/14 = 0.04
"""

data

from sklearn import naive_bayes as nb
multiNomModel = naive_bayes.MultinomialNB()
multiNomModel

print(data["outlook"])
data = data.apply(lambda y:y.astype(dtype='category'))
print(data["outlook"])

data.iloc[:, :4]

# multiNomModel.fit(data.iloc[:, :4], data["play"])
data.info()
data

outlookDic = {"overcast":0, "rainy":1, "sunny":2 }
tempDic = {"cool":0, "hot":1, "mild":2 }
humidDic = {"high":0, "normal":1}
windyDic = {False:0, True:1}

data["outlook"] = data["outlook"].map(outlookDic)
data["temperature"] = data["temperature"].map(tempDic)
data["humidity"] = data["humidity"].map(humidDic)
data["windy"] = data["windy"].map(windyDic)
data

multiNomModel.fit(data.iloc[:, :4], data["play"])

multiNomModel.predict([[2,2,0,1]]) 
# Outlook = Sunny, Temperature = Mild,Humidity = High, Windy = True

multiNomModel.predict_proba([[2,2,0,1]])

from sklearn.datasets import load_iris
iris = load_iris()
irisDF = pd.DataFrame(iris.data, columns=iris.feature_names)
irisDF["species"] = iris.target
irisDF.head()

gaussianModel = naive_bayes.GaussianNB()

from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(
    irisDF.iloc[:,:4], irisDF["species"], test_size=0.33)
gaussianModel.fit(xTrain, yTrain)

from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(yTest, gaussianModel.predict(xTest)))
print(confusion_matrix(yTest, gaussianModel.predict(xTest)))