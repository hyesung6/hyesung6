# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G5S5UgTacKsyoYamGexB0HpHGopKPahL
"""

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

data = load_breast_cancer()
xTrain, xTest, yTrain, yTest = train_test_split(data.data, data.target, random_state=42)
model = DecisionTreeClassifier(criterion='entropy')
model.get_params

yPred = model.fit(xTrain, yTrain)
yPred = model.predict(xTest)
yPred

from sklearn.preprocessing import StandardScaler
xTrain

scaler = StandardScaler()
# scaler.fit(xTrain)
# xTrain = scaler.transform(xTrain)
xTrain = scaler.fit_transform(xTrain)

xTrain

from sklearn.datasets import load_iris
data = load_iris()
data.target

data.keys()

print(data.DESCR)

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

features = pd.DataFrame(data=data.data, columns=data.feature_names)
features

target = pd.DataFrame(data.target, columns=["species"])
target

iris = pd.concat([features, target], axis=1)
iris

iris.rename({"sepal length (cm)":"sepal length", 	"sepal width (cm)":"sepal width",	"petal length (cm)":"petal length", 	"petal width (cm)":"petal width"}, axis=1, inplace=True)
iris

iris["species"] = iris.species.map(lambda x:data.target_names[x])
iris

iris.isna().sum(axis=0)

iris

iris.info()

iris.describe()

iris.corr()

iris.groupby("species").size()

def boxplot_iris(feature_names, dataset):
  i=1
  plt.figure(figsize=(11, 9))
  for col in feature_names:
    plt.subplot(2,2,i)
    plt.axis("on")
    plt.tick_params(axis="both", left=True, top=False, right=False, bottom=True, labelleft=True, labeltop=False, labelright=False, labelbottom=False)
    dataset[col].plot(kind='box', subplots=True, sharex=False, sharey=False)
    plt.title(col)
    i +=1
  plt.show()

boxplot_iris(iris.columns[:-1], iris)

def histogram_iris(feature_names, dataset):
  i=1
  plt.figure(figsize=(11, 9))
  for col in feature_names:
    plt.subplot(2,2,i)
    plt.axis("on")
    plt.tick_params(axis="both", left=True, top=False, right=False, bottom=True, labelleft=True, labeltop=False, labelright=False, labelbottom=False)
    dataset[col].hist()
    plt.title(col)
    i +=1
  plt.show()

histogram_iris(iris.columns[:-1], iris)

corr = iris.corr()
cmap = sns.diverging_palette(220, 10, as_cmap=True)

plt.figure(figsize=(11, 9))
sns.heatmap(corr, cmap=cmap, vmax=1.0, center = 0, square=True, linewidths=.5, cbar_kws={"shrink":.5})
plt.show()

sns.pairplot(iris, hue="species")
plt.show()

def piechart_iris(feature_names, target, dataset):
  i=1
  plt.figure(figsize=(11, 9))
  for colName in [target]:
    labels=[]; sizes=[]
    df = dataset.groupby(colName).size()
    for key in df.keys():
      labels.append(key)
      sizes.append(df[key])
    plt.subplot(2,2,i)
    plt.axis("on")
    plt.tick_params(axis="both", left=True, top=False, right=False, bottom=True, labelleft=False, labeltop=True, labelright=False, labelbottom=False)
    plt.pie(sizes, labels=labels, autopct="%1.1f%%", shadow=True, startangle=150)
    plt.axis("equal")
    i +=1
  plt.show()

piechart_iris(iris.columns[:-1], iris.species, iris)

from sklearn.model_selection import train_test_split
xTrain, xTest, yTrain, yTest = train_test_split(iris.iloc[:, :-1], iris.iloc[:, -1], test_size=0.4, random_state=42)
xTrain

yTrain

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(criterion="gini", splitter="best", max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=42, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None)
model

model.fit(xTrain, yTrain)

yPredict = model.predict(xTest)
yPredict

yTest

model.score(xTest, yTest) # 90개 학습

import sklearn
sklearn.__version__

from sklearn.model_selection import cross_val_score, KFold
cv=KFold(n_splits=10, shuffle=True, random_state=42)
results = cross_val_score(model, xTrain, yTrain, cv=cv)
fin_result = np.mean(results)

for i, _ in enumerate(results):
  print("{}번째 교차검증 정확도 : {}".format(i, _))
print("\n교차검증 정확도 : {}".format(fin_result))

from sklearn.model_selection import StratifiedKFold
cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
results = cross_val_score(model, xTrain, yTrain, cv=cv)
fin_result = np.mean(results)

for i, _ in enumerate(results):
  print("{}번째 교차검증 정확도 : {}".format(i, _))
print("\n교차검증 정확도 : {}".format(fin_result))

!pip install scikit-plot
import scikitplot as skplt
skplt.estimators.plot_learning_curve(model, xTrain, yTrain, figsize=(6,6))
plt.show()

#!pip install sci-kitlearn
from sklearn.model_selection import GridSearchCV
estimator = DecisionTreeClassifier()
parameters = {"max_depth" : [4,6,8,10, 12],
             "criterion" : ["gini", "entropy"],
             "splitter" : ["best", "random"],
             "min_weight_fraction_leaf":[0.0,0.1,0.2,0.3],
             "random_state":[7, 23, 42, 78, 142],
             "min_impurity_decrease":[0.0,0.05, 0.1, 0.2]}
model = GridSearchCV(estimator=estimator, param_grid=parameters, cv = cv, verbose=1, n_jobs = -1, refit=True)
model.fit(xTrain, yTrain)

print("Best Estimator:\n", model.best_estimator_); print()
print("Best Params:\n", model.best_params_); print()
print("Best Score:\n", model.best_score_)

from sklearn.metrics import accuracy_score

yPred = model.predict(xTest)
acc = accuracy_score(yTest, yPred)
print("Accuracy : " , acc)

from sklearn.metrics import confusion_matrix

confMatrix = confusion_matrix(yTest, yPred)
print("Confusion Matrix :\n", confMatrix)

skplt.metrics.plot_confusion_matrix(yTest, yPred, figsize=(8,6))
plt.show()

from sklearn.metrics import precision_score

yPrecis = precision_score(yTest, yPred, average=None)
for target, score in zip(data.target_names, yPrecis) :
  print(f"{target}의 정밀도 :  {score}")

from sklearn.metrics import recall_score

yRecalls = recall_score(yTest, model.predict(xTest), average=None)

for target, score in zip(data.target_names, yRecalls) :
  print(f"{target}의 재현율 :  {score}")